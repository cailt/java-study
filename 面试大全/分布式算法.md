## base paxos
https://sevenvoid.github.io/2017-06-27-paxos/

## multi paxos
https://www.huaweicloud.com/articles/1161000c1e8860fc9220edd3de7c45af.html

## ZAB
https://blog.csdn.net/liuchang19950703/article/details/111406622
- 奔溃恢复
leader选举
1）选 epoch 最大的
2）若 epoch 相等，选 zxid 最大的
3）若 epoch 和 zxid 相等，选择 server_id 最大的（zoo.cfg中的myid）
数据同步
获取follower最大zxid，同步差量部分。
- 消息广播
跟raft类似。
## raft
https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md
https://blog.csdn.net/weixin_33862993/article/details/91473548
- leader选举
候选人：随机时间，任期+1；
随从者：只为日志不比自己小的候选人投票，每一任期只会投票一次。
- 日志复制
正常请求：写日志，广播出去，应用到状态机，发起提交
数据同步：先做一致性校验，nextIndex=leader的最大日志加1，尝试同步给从节点，同步失败，则nextIndex-1，一直重试，直到某个点一致，删掉从节点从该一致性点之后的数据，leader从该点开始发起日志复制。
- 安全性
随从者：只为日志不比自己小的候选人投票；
提交老leader日志：当新leader第一次处理客户端请求的时候，顺便复制老leader的日志。（防止已提交日志被覆盖）

## paxos、raft、zab区别
https://my.oschina.net/pingpangkuangmo/blog/782702

## gossip
https://cloud.tencent.com/developer/article/1662426
https://zhuanlan.zhihu.com/p/41228196
https://juejin.cn/post/6930774718114955278

## 2PC、3PC
https://yuck1125.github.io/2019/07/15/XA-2PC-3PC/
https://www.cnblogs.com/qdhxhz/p/11167025.html
https://blog.csdn.net/luzhensmart/article/details/112984528
https://juejin.cn/post/6844903814898647048?share_token=7d90687f-f140-4dd2-828d-ae7351b7c109
都没法解决事务一致性问题。

## 分布式事务
http://www.dockone.io/article/10811
https://xiaomi-info.github.io/2020/01/02/distributed-transaction/
https://segmentfault.com/a/1190000040321750

### tcc
https://www.cnblogs.com/zhengzhaoxiang/p/13976524.html   写的一般
https://www.javazhiyin.com/44745.html
https://xie.infoq.cn/article/e6539ce436294828b5c9420f9
https://www.cnblogs.com/jajian/p/10014145.html

confirm和cancel就是补偿事务，用于取消try阶段本地事务造成的影响。因为第一阶段try只是预留资源，之后必须要明确的告诉服务提供者，这个资源你到底要不要，对应第二阶段的confirm/cancel。

主业务方重启问题？需要持久化：
1、事务日志（执行的数据，接口信息）；
2、事务状态（执行到哪个阶段了）；
![image.png](https://upload-images.jianshu.io/upload_images/24337324-46a12398c9047411.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
1. 当所有 try 接口调用完成，事务状态还没来得及改变为 confirm 时，此时事务状态处于 try 状态，崩溃重启后回滚事务。
2. 当所有 confirm 接口调用完成，事务状态还没来得及改变为 end 时，此时事务处于 confirm 状态，崩溃重启后继续调 confirm 提交事务。
3. 当所有 cancel 接口调用完成，事务状态还没来得及改变为 end 时，此时事务处于 cancel 状态，崩溃重启后继续调 cancel 回滚事务。

幂等性、空回滚、悬挂问题？
![image.png](https://upload-images.jianshu.io/upload_images/24337324-6de3b3809516fd00.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

https://blog.csdn.net/xiaozhu0301/article/details/111322711

### 可靠消息与最大努力通知
https://blog.csdn.net/u010821757/article/details/103675912
https://juejin.cn/post/6844904099993878536
https://www.cnblogs.com/blogtech/p/14513002.html
https://www.jianshu.com/p/3b1a8e259910 
#### 问题消费方失败如何回滚
https://www.oschina.net/question/2491333_2312233

### Seata（后续可以学习）
http://seata.io/zh-cn/docs/overview/what-is-seata.html
https://www.jianshu.com/p/044e95223a17
### 隔离级别与全局锁
https://blog.csdn.net/a294634473/article/details/121069447?share_token=76cd04b5-440a-45cb-add1-ffc6eb5ac655
https://database.51cto.com/art/202112/696738.htm?share_token=6e24f046-ad52-4b28-acbc-b95e9f5dfc32 赞赞赞全局锁

### 一致性hash算法
https://juejin.cn/post/6844903750860013576
https://aijishu.com/a/1060000000007241
https://cloud.tencent.com/developer/article/1522821
https://gongfukangee.github.io/2019/05/19/Hash/ 赞赞赞
hash算法缺点：
1.由于key和host之间关系是通过哈希算法算出来的，所以这种映射比较固定，不灵活。比如想把key1,key2,key3都映射到hostA处理，除非这三个key真的通过哈希算出来映射到hostA，否则不容易做到。
2.解决了数据分布的均匀性，但数据/key的均匀，不代表流量和负载的均匀。可能有的key访问量大，有的访问量小，导致实际节点负载并不均匀。

注意：下一步需要比较一下redis哈希槽算法的优缺点
